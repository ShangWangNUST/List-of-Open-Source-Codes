# Attention Mechanisem


## Attention Mechanisem

### 2017
* Attention Is All You Need. ([Tensor2Tensor](https://github.com/tensorflow/tensor2tensor), [PyTorch](https://github.com/jadore801120/attention-is-all-you-need-pytorch))

## Attention Autoencoders (Papers)

### 2022
* Attention-based residual autoencoder for video anomaly detection. ([PyTorch](https://github.com/vt-le/astnet))


## Attention CNN (Papers)

### 2018
* CBAM: Convolutional Block Attention Module ([TensorFlow](https://github.com/kobiso/CBAM-keras))

### 2019
* Dual Attention Network for Scene Segmentation. ([Pytorch](https://github.com/junfu1115/DANet/))
* CondConv Conditionally Parameterized Convolutions for Efficient Inference. ([TensorFlow](https://github.com/prstrive/CondConv-tensorflow))
* Stand-Alone Self-Attention in Vision Models. ([Pytorch](https://github.com/MartinGer/Stand-Alone-Self-Attention-in-Vision-Models))

### 2020
* Multi-scale self-guided attention for medical image segmentation. ([Pytorch](https://github.com/sinAshish/Multi-Scale-Attention))
* ECA-Net Efficient Channel Attention for Deep Convolutional Neural Networks. ([Pytorch](https://github.com/BangguWu/ECANet))
* On the Relationship between Self-Attention and Convolutional Layers. ([PyTorch](https://github.com/epfml/attention-cnn))
* Attention Augmented Convolutional Networks ([TensorFlow](https://github.com/titu1994/keras-attention-augmented-convs), [Pytorch](https://github.com/leaderj1001/Attention-Augmented-Conv2d))
* Dynamic Convolution Attention over Convolution Kernels ([Pytorch](https://github.com/kaijieshi7/Dynamic-convolution-Pytorch))
* Dilated Convolutional Attention Network for Medical Code Assignment from Clinical Text. ([Pytorch](https://github.com/shaoxiongji/DCAN))

### 2022
* Visual Attention Network. ([Pytorch](https://github.com/Visual-Attention-Network/VAN-Classification))
* Attention mechanisms in computer vision A survey. ([PDF](https://github.com/MenghaoGuo/Awesome-Vision-Attentions))


### Repositories
* Pytorch implementation of various Attention Mechanisms, MLP, Re-parameter, Convolution, which is helpful to further understand papers. ([Pytorch](https://github.com/xmu-xiaoma666/External-Attention-pytorch#10-Pyramid-Split-Attention-Usage))


## Attention GAN (Papers)

### 2019
* Self-Attention Generative Adversarial Networks. ([TensorFlow](https://github.com/brain-research/self-attention-gan), [Pytorch](https://github.com/heykeetae/Self-Attention-GAN))
